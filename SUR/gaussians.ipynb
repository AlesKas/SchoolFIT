{
    "cells": [
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "colab": {},
       "colab_type": "code",
       "id": "L0AMLQhRPc39"
      },
      "outputs": [],
      "source": [
       "import matplotlib.pyplot as plt\n",
       "plt.rcParams.update({'figure.figsize': (8.0, 8.0), 'font.size': 18})\n",
       "import numpy as np\n",
       "import math\n",
       "from scipy.spatial.distance import cdist\n",
       "\n",
       "def rand_gauss(n, mu, cov):\n",
       "    if cov.ndim == 1:\n",
       "        cov = np.diag(cov)\n",
       "    assert(mu.ndim == 1 and len(mu) == len(cov) and cov.ndim == 2 and cov.shape[0] == cov.shape[1])\n",
       "    d, v = np.linalg.eigh(cov)\n",
       "    return (np.random.randn(n, len(mu)) * np.sqrt(d)).dot(v) + mu\n",
       "\n",
       "def logpdf_gauss(x, mu, cov):\n",
       "    assert(mu.ndim == 1 and len(mu) == len(cov) and (cov.ndim == 1 or cov.shape[0] == cov.shape[1]))\n",
       "    x = np.atleast_2d(x) - mu\n",
       "    return -0.5*(len(mu)*np.log(2 * np.pi) + np.linalg.slogdet(cov)[1] + np.sum(x.dot(np.linalg.inv(cov)) * x, axis=1))\n",
       "      \n",
       "def plot2dfun(f, limits, resolution, ax=None):\n",
       "    if ax is None:\n",
       "        ax = plt\n",
       "    xmin, xmax, ymin, ymax = limits\n",
       "    xlim = np.arange(ymin, ymax, (ymax - ymin) / float(resolution))\n",
       "    ylim = np.arange(xmin, xmax, (xmax - xmin) / float(resolution))\n",
       "    a, b = np.meshgrid(ylim, xlim)\n",
       "    img = f(np.vstack([np.ravel(a), np.ravel(b)[::-1]]).T)\n",
       "    img = (img - img.min()) /(img.max() - img.min()) # normalize to range 0.0 - 1.0\n",
       "    img = img.reshape(a.shape+img.shape[1:])\n",
       "    return ax.imshow(img, cmap='gray', aspect='auto', extent=(xmin, xmax, ymin, ymax))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "colab_type": "text",
       "id": "ellaLv1zRAjY"
      },
      "source": [
       "# K-nearest neighbours example"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "colab": {},
       "colab_type": "code",
       "id": "bISdY5TGP1T0"
      },
      "outputs": [],
      "source": [
       "%matplotlib inline\n",
       "plt.rcParams.update({'figure.figsize': (8.0, 8.0), 'font.size': 18})\n",
       "\n",
       "\n",
       "def k_nearest_neighbours(test_data, class1, class2, k):\n",
       "    euclidean = cdist(np.r_[class1, class2], test_data)\n",
       "    i = np.argsort(euclidean.T)\n",
       "    return np.sum(i[:,:k] >= len(class1), axis=1) / float(k)\n",
       "\n",
       "\n",
       "x1 = rand_gauss(100, np.array([50, 50]), np.array([[100, 70], [70, 100]]))\n",
       "x2 = rand_gauss(200, np.array([40, 60]), np.array([[40, 0], [0, 40]]))\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "ax = plt.axis()\n",
       "\n",
       "k = 9\n",
       "\n",
       "def soft_score(x):\n",
       "  return k_nearest_neighbours(x, x1, x2, k)\n",
       "\n",
       "def hard_decision(x):\n",
       "  return (soft_score(x) > 0.5).astype(float)\n",
       "\n",
       "plt.figure()\n",
       "plot2dfun(hard_decision, ax, 500)\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "\n",
       "plt.figure()\n",
       "plot2dfun(soft_score, ax, 500)\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "colab_type": "text",
       "id": "8QDXotpfRfh-"
      },
      "source": [
       "# Examples of 2D Multivariate Gaussian distribution"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/",
        "height": 548
       },
       "colab_type": "code",
       "executionInfo": {
        "elapsed": 1197,
        "status": "ok",
        "timestamp": 1563426010119,
        "user": {
         "displayName": "lukas",
         "photoUrl": "",
         "userId": "16549058022837008943"
        },
        "user_tz": -120
       },
       "id": "gCasOIsaQ-pu",
       "outputId": "074fb7a1-9346-4ea2-f04e-afba8886099b"
      },
      "outputs": [],
      "source": [
       "mu  = np.array([0.0, 0.0])\n",
       "cov = np.array([[4.0, -0.8],\n",
       "                [-0.8, 1.0]])\n",
       "x = rand_gauss(500, mu, cov)\n",
       "plt.plot(x[:,0], x[:,1], 'r.', markersize=2)\n",
       "ax = plt.axis()\n",
       "\n",
       "np.exp(logpdf_gauss(x, mu, cov))\n",
       "plt.axis('equal')\n",
       "plot2dfun(lambda x: 1-np.exp(logpdf_gauss(x, mu, cov)), ax, 500)\n",
       "plt.title(r'$\\mu=\\binom{'+str(mu[0])+'}{'+str(mu[1])+r'}\\Sigma=\\binom{'+str(cov[0,0])+r'\\ \\ '+str(cov[0,1])+r'}{'+str(cov[1,0])+r'\\ \\ '+str(cov[1,1])+ r'}$', fontsize=24, pad=15)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "colab_type": "text",
       "id": "NtABQiuaSCVq"
      },
      "source": [
       "# Example of Gaussian classifier"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "colab": {
        "base_uri": "https://localhost:8080/",
        "height": 1000
       },
       "colab_type": "code",
       "executionInfo": {
        "elapsed": 1740,
        "status": "ok",
        "timestamp": 1563425603879,
        "user": {
         "displayName": "lukas",
         "photoUrl": "",
         "userId": "16549058022837008943"
        },
        "user_tz": -120
       },
       "id": "0ZlNecXVSCvo",
       "outputId": "360d1137-b9de-470d-8572-6e5d110fce50"
      },
      "outputs": [],
      "source": [
       "%matplotlib inline\n",
       "plt.rcParams.update({'figure.figsize': (8.0, 8.0), 'font.size': 18})\n",
       "\n",
       "#Generate random data for classes x1, x2 and x3. The data for each class are\n",
       "#generated from two gaussian distributions.\n",
       "np.random.seed(0)\n",
       "x1 = rand_gauss(400, np.array([45, 60]), np.array([[40, 0],   [0, 40]]))\n",
       "x2 = rand_gauss(600, np.array([50, 40]), np.array([[100, 80], [80, 100]]))\n",
       "x3 = rand_gauss(500, np.array([30, 50]), np.array([[40, -10], [-10, 40]]))\n",
       "\n",
       "mus  = [np.mean(x, axis=0) for x in [x1, x2, x3]]\n",
       "covs = [np.cov(x.T) for x in [x1, x2, x3]]\n",
       "N = np.array([len(x1), len(x2), len(x3)], dtype=float)\n",
       "P = N/N.sum()\n",
       "\n",
       "# Plot the data\n",
       "plt.plot(\n",
       "    x1[:,0], x1[:,1], 'r.', \n",
       "    x2[:,0], x2[:,1], 'g.',\n",
       "    x3[:,0], x3[:,1], 'b.',\n",
       "    markersize=5, markeredgecolor='w', markeredgewidth=0\n",
       ")\n",
       "plt.xlabel('$x_1$', fontsize=16)\n",
       "plt.ylabel('$x_2$', fontsize=16)\n",
       "ax = plt.axis()\n",
       "\n",
       "plt.figure()\n",
       "\n",
       "def pdfs_for_all_classes(x):\n",
       "  return np.vstack([np.exp(logpdf_gauss(x, mu, cov)) for mu, cov in zip(mus, covs)]).T\n",
       "  \n",
       "plot2dfun(pdfs_for_all_classes, ax, 500)\n",
       "plt.xlabel('$x_1$', fontsize=16)\n",
       "plt.ylabel('$x_2$', fontsize=16)\n",
       "\n",
       "# compute posterior probability for class X1\n",
       "def x1_posterior(x):\n",
       "  joint_prob = pdfs_for_all_classes(x) * P\n",
       "  return  joint_prob / joint_prob.sum(axis=1, keepdims=True)\n",
       "\n",
       "\n",
       "# Plot the data with the posterior probability as the background\n",
       "plt.figure()\n",
       "plot2dfun(x1_posterior, ax, 500)\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', \n",
       "         x2[:,0], x2[:,1], 'g.',\n",
       "         x3[:,0], x3[:,1], 'b.',\n",
       "         markersize=7, markeredgecolor='k', markeredgewidth=0.5)\n",
       "plt.xlabel('$x_1$', fontsize=16)\n",
       "plt.ylabel('$x_2$', fontsize=16)\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Classifying non-Gaussian data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def compute_ellipse(mu, cov, n):\n",
       "    mu = mu.copy()\n",
       "    if mu.shape == (2,):\n",
       "        mu.shape = (2, 1)\n",
       "    if mu.shape != (2, 1) or cov.shape != (2, 2):\n",
       "        raise RuntimeError('mu must be a two element vector and cov must be 2 x 2 matrix')\n",
       "\n",
       "    d, v = np.linalg.eigh(4 * cov)\n",
       "    d = np.diag(d)\n",
       "    t = np.linspace(0, 2 * math.pi, n)\n",
       "    x = v @ np.sign(d) @ np.sqrt(np.abs(d)) @ np.array([np.cos(t), np.sin(t)]) + mu\n",
       "    \n",
       "    return x\n",
       "    \n",
       "\n",
       "def gellipse(mu, cov, n=100, *args, **kwargs):\n",
       "    \"\"\"\n",
       "    Contour plot of 2D Multivariate Gaussian distribution.\n",
       "\n",
       "    gellipse(mu, cov, n) plots ellipse given by mean vector MU and\n",
       "    covariance matrix COV. Ellipse is plotted using N (default is 100)\n",
       "    points. Additional parameters can specify various line types and\n",
       "    properties. See description of matplotlib.pyplot.plot for more details.\n",
       "    \"\"\"\n",
       "    x = compute_ellipse(mu, cov, n)\n",
       "    return plt.plot(x[0], x[1], *args, **kwargs)\n",
       "\n",
       "\n",
       "def train_gauss(x):\n",
       "    \"\"\"\n",
       "    Estimates gaussian distribution from data.\n",
       "    (MU, COV) = TRAIN_GAUSS(X) return Maximum Likelihood estimates of mean\n",
       "    vector and covariance matrix estimated using training data X\n",
       "    \"\"\"\n",
       "    return np.mean(x, axis=0), np.cov(x.T, bias=True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%matplotlib inline\n",
       "plt.rcParams.update({'figure.figsize': (8.0, 8.0), 'font.size': 18})\n",
       "\n",
       "#Generate random data for classes X1 and X2. The data for each class are\n",
       "#generated from two gaussian distributions. Hopefully, we will be able to\n",
       "#learn these distributions from data using EM algorithm implemented in \n",
       "#'train_gmm' function.\n",
       "x1 = np.r_[rand_gauss(400, np.array([50, 40]), np.array([[100, 70], [70, 100]])),\n",
       "           rand_gauss(200, np.array([55, 75]), np.array([[25, 0], [0, 25]]))]\n",
       "          \n",
       "x2 = np.r_[rand_gauss(400, np.array([45, 60]), np.array([[40, 0], [0, 40]])),\n",
       "           rand_gauss(200, np.array([30, 40]), np.array([[20, 0], [0, 40]]))]\n",
       "\n",
       "print(x1.shape)\n",
       "\n",
       "mu1, cov1 = train_gauss(x1)\n",
       "mu2, cov2 = train_gauss(x2)\n",
       "p1 = p2 = 0.5\n",
       "\n",
       "# Plot the data\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "plt.show()\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%matplotlib inline\n",
       "plt.rcParams.update({'figure.figsize': (8.0, 8.0), 'font.size': 18})\n",
       "\n",
       "def hard_decision(x):\n",
       "    class_1 = logpdf_gauss(x, mu1, cov1) + np.log(p1) > logpdf_gauss(x, mu2, cov2) + np.log(p2)\n",
       "    return class_1.astype(np.float)\n",
       "    \n",
       "def x1_posterior(x):\n",
       "    joint_1 = np.exp(logpdf_gauss(x, mu1, cov1) + np.log(p1))\n",
       "    joint_2 = np.exp(logpdf_gauss(x, mu2, cov2) + np.log(p2))\n",
       "    Z = joint_1 + joint_2\n",
       "    return joint_1 / Z\n",
       "\n",
       "\n",
       "plt.figure()\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "ax = plt.axis()\n",
       "gellipse(mu1, cov1, 100, 'r')\n",
       "gellipse(mu2, cov2, 100, 'b')\n",
       "plt.show()\n",
       "\n",
       "plt.figure(figsize=(16, 8))\n",
       "plt.subplot(121)\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "plot2dfun(hard_decision, ax, 100)\n",
       "\n",
       "plt.subplot(122)\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "plot2dfun(x1_posterior, ax, 100)\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Building a GMM classifier"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%matplotlib inline\n",
       "plt.rcParams.update({'figure.figsize': (8.0, 8.0), 'font.size': 18})\n",
       "\n",
       "# Initialize 2 GMM models with full covariance matrices\n",
       "m1 = 2  # Number of components\n",
       "mus1 = x1[np.random.randint(1, len(x1), m1)]  #  Initialize means to random points from given class\n",
       "covs1 = [cov1] * m1 #  Use the full cov matrix for both components\n",
       "ws1 = np.ones(m1) / m1 #  Use uniform distribution as initial guess for the weights\n",
       "\n",
       "m2 = 2\n",
       "mus2 = x2[np.random.randint(1, len(x2), m2)]\n",
       "covs2 = [cov2] * m2\n",
       "ws2 = np.ones(m2) / m2\n",
       "\n",
       "\n",
       "class GMMPlot:\n",
       "    def __init__(self, fig, ax, color, ws, mus, covs):\n",
       "        self.fig = fig\n",
       "        \n",
       "        self.ellipsae = []\n",
       "        for w, mu, cov in zip(ws, mus, covs):\n",
       "            x = compute_ellipse(mu, cov, n=100)\n",
       "            e_plot = ax.plot(x[0], x[1], color, lw=10*w)\n",
       "            self.ellipsae.append(e_plot[0])\n",
       "        self.fig.canvas.draw()\n",
       "        \n",
       "    def update(self, ws, mus, covs):\n",
       "        for e_plot, w, mu, cov in zip(self.ellipsae, ws, mus, covs):\n",
       "            x = compute_ellipse(mu, cov, n=100)\n",
       "            e_plot.set_xdata(x[0])\n",
       "            e_plot.set_ydata(x[1])\n",
       "            e_plot.set_linewidth(10*w)\n",
       "\n",
       "        self.fig.canvas.draw()\n",
       "            \n",
       "fig, ax = plt.subplots(1, 1)\n",
       "ax.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "GMMPlot(fig, ax, 'r', ws1, mus1, covs1)\n",
       "GMMPlot(fig, ax, 'b', ws2, mus2, covs2)\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from scipy.special import logsumexp\n",
       "def train_gmm(x, ws, mus, covs):\n",
       "    # E-step\n",
       "    log_gamma = np.vstack([np.log(w) + logpdf_gauss(x, m, c) for w, m, c in zip(ws, mus, covs)])\n",
       "    logevidence = logsumexp(log_gamma, axis=0) #  Marginalize components\n",
       "    gamma = np.exp(log_gamma - logevidence)\n",
       "    tll = logevidence.sum()\n",
       "    gammasum = gamma.sum(axis=1) #  Marginalize datapoints\n",
       "    \n",
       "    # M-step\n",
       "    ws = gammasum / len(x) # Normalize total responsibility by the number of datapoints\n",
       "    mus = gamma @ x / gammasum[:, np.newaxis]\n",
       "    covs = np.array([(gamma[i] * x.T) @ x / gammasum[i] - np.outer(mus[i], mus[i]) for i in range(len(ws))])\n",
       "    \n",
       "    return ws, mus, covs, tll\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "%matplotlib nbagg\n",
       "import time\n",
       "fig, ax = plt.subplots(1,1)\n",
       "ax.plot(x1[:,0], x1[:,1], 'r.', x2[:,0], x2[:,1], 'b.')\n",
       "gmm_plot_1 = GMMPlot(fig, ax, 'r', ws1, mus1, covs1)\n",
       "gmm_plot_2 = GMMPlot(fig, ax, 'b', ws2, mus2, covs2)\n",
       "time.sleep(4)\n",
       "for i in range(30):\n",
       "    ws1, mus1, covs1, tll1 = train_gmm(x1, ws1, mus1, covs1)\n",
       "    ws2, mus2, covs2, tll2 = train_gmm(x2, ws2, mus2, covs2)\n",
       "    gmm_plot_1.update(ws1, mus1, covs1)\n",
       "    gmm_plot_2.update(ws2, mus2, covs2)\n",
       "    \n",
       "    time.sleep(0.7)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def logpdf_gmm(x, ws, mus, covs):\n",
       "    return logsumexp([np.log(w) + logpdf_gauss(x, m, c) for w, m, c in zip(ws, mus, covs)], axis=0)\n",
       "\n",
       "%matplotlib inline\n",
       "plt.rcParams.update({'figure.figsize': (8.0, 8.0), 'font.size': 18})\n",
       "\n",
       "def hard_decision(x):\n",
       "    log_joint_1 = logpdf_gmm(x, ws1, mus1, covs1) + np.log(p1)\n",
       "    log_joint_2 = logpdf_gmm(x, ws2, mus2, covs2) + np.log(p2)\n",
       "    return  (log_joint_1 > log_joint_2).astype(np.float)\n",
       "\n",
       "def soft_decision(x):\n",
       "    joint_1 = np.exp(logpdf_gmm(x, ws1, mus1, covs1) + np.log(p1))\n",
       "    joint_2 = np.exp(logpdf_gmm(x, ws2, mus2, covs2) + np.log(p2))\n",
       "    Z = joint_1 + joint_2\n",
       "    return  joint_1 / Z\n",
       "        \n",
       "\n",
       "plt.figure(figsize=(16, 8))\n",
       "plt.subplot(121)\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.')\n",
       "plt.plot(x2[:,0], x2[:,1], 'b.')\n",
       "plot2dfun(hard_decision, plt.axis(), 500)\n",
       "\n",
       "plt.subplot(122)\n",
       "plt.plot(x1[:,0], x1[:,1], 'r.')\n",
       "plt.plot(x2[:,0], x2[:,1], 'b.')\n",
       "plot2dfun(soft_decision, plt.axis(), 500)\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "colab": {
      "collapsed_sections": [],
      "name": "Copy of Untitled3.ipynb",
      "provenance": [
       {
        "file_id": "1X5rSsLvdKF2Gr3NdXvlC75TjnB_cR0HY",
        "timestamp": 1563427377994
       }
      ],
      "version": "0.3.2"
     },
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 1
   }