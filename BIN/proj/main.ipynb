{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from eval import accuracy\n",
    "from model import MnistCNN\n",
    "from train import fit, evaluate\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SIZE = 28 * 28\n",
    "DATASET = MNIST(root='data/', download=True, train=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "\n",
    "def split_indices(n, val_pct):\n",
    "    # Determine size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "\n",
    "    idxs = np.random.permutation(n)\n",
    "\n",
    "    return idxs[n_val:], idxs[:n_val]\n",
    "\n",
    "train_indexes, validation_indexes = split_indices(len(DATASET), 0.2)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indexes)\n",
    "train_loader = DataLoader(DATASET, BATCH_SIZE, sampler=train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(validation_indexes)\n",
    "val_loader = DataLoader(DATASET, BATCH_SIZE, sampler=val_sampler)\n",
    "\n",
    "loss_fun = F.cross_entropy\n",
    "\n",
    "def predict_image(image, model):\n",
    "    xb = image.unsqueeze(0).to(dev)\n",
    "    yb = model(xb)\n",
    "    yb = yb.to(dev)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()\n",
    "\n",
    "def plot_graph(rng ,acc_list, lost_list, title):\n",
    "    plt.plot(rng, acc_list, '-b', label='accuracy')\n",
    "    plt.plot(rng, lost_list, '-r', label='loss')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(\"amount pruned\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.1084, accuracy: 0.9677\n",
      "Epoch 2, loss: 0.0766, accuracy: 0.9753\n",
      "Epoch 3, loss: 0.0820, accuracy: 0.9737\n",
      "Epoch 4, loss: 0.0714, accuracy: 0.9793\n",
      "Epoch 5, loss: 0.0730, accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = MnistCNN().to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "fit(5, model, loss_fun, optimizer, train_loader, val_loader, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0614, accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MNIST(root='data/', train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "test_loss, total, test_acc = evaluate(model, loss_fun, test_loader, metric=accuracy)\n",
    "print(f\"Loss: {test_loss:.4f}, accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output\n",
    "    return hook\n",
    "\n",
    "for name, module in model.named_children():\n",
    "    module.register_forward_hook(get_activation(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name, input, output):\n",
    "    print(f\"{name} {input[0].shape} {output.shape}\")\n",
    "\n",
    "for name, module in model.named_children():\n",
    "    module.register_forward_hook(get_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRP_0(model : nn.Module, X):\n",
    "    layers = [module for module in model.named_children() if not isinstance(module, torch.nn.Sequential)]\n",
    "    L = len(layers)\n",
    "    A = [X] + [X] * L \n",
    "    for layer in range(L):\n",
    "        if layers[layer][0] == 'pool1':\n",
    "            pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, return_indices=True)\n",
    "            output1, indices1 = pool(A[layer])\n",
    "            A[layer + 1] = output1\n",
    "            continue\n",
    "        if layers[layer][0] == 'pool2':\n",
    "            pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, return_indices=True)\n",
    "            output2, indices2 = pool(A[layer])\n",
    "            A[layer + 1] = output2\n",
    "            continue\n",
    "        A[layer + 1] = layers[layer][1].forward(A[layer])\n",
    "\n",
    "    T = A[-1].cpu().detach().numpy().tolist()[0]\n",
    "    index = T.index(max(T))\n",
    "    T = np.abs(np.array(T)) * 0\n",
    "    T[index] = 1\n",
    "    T = torch.FloatTensor(T)\n",
    "    # Create the list of relevances with (L + 1) elements and assign the value of the last one \n",
    "    R = [None] * L + [(A[-1].cpu() * T).data + 1e-6]\n",
    "    for layer in range(0, L)[::-1]:\n",
    "        if layers[layer][0] == 'flatten':\n",
    "            R[layer] = torch.reshape(A[layer], (32,7,7))\n",
    "            continue\n",
    "        if layers[layer][0] == 'pool2':\n",
    "            unpool = nn.MaxUnpool2d(kernel_size=2)\n",
    "            R[layer] = unpool(A[layer+1], indices2)\n",
    "            continue\n",
    "        if layers[layer][0] == 'pool1':\n",
    "            unpool = nn.MaxUnpool2d(kernel_size=2)\n",
    "            R[layer] = unpool(A[layer+1], indices1)\n",
    "            continue\n",
    "        if layers[layer][0] == 'relu1' or layers[layer][0] == 'relu2':\n",
    "            R[layer] = A[layer + 1]\n",
    "            continue\n",
    "        A[layer] = A[layer].data.requires_grad_(True)\n",
    "        z = newlayer(layers[layer][1]).forward(A[layer]) + 1e-9\n",
    "        s = (R[layer+1].to(dev) / z).data\n",
    "        (z * s).sum().backward()\n",
    "        c = A[layer].grad\n",
    "        R[layer] = (A[layer] * c).cpu().data \n",
    "    return R[0]\n",
    "        \n",
    "\n",
    "\n",
    "def newlayer(layer : nn.Module) -> nn.Module:\n",
    "    layer = copy.deepcopy(layer)\n",
    "    layer.weight = torch.nn.Parameter(layer.weight)\n",
    "    layer.bias = torch.nn.Parameter(layer.bias)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) torch.Size([1, 1, 28, 28]) torch.Size([1, 16, 28, 28])\n",
      "ReLU() torch.Size([1, 16, 28, 28]) torch.Size([1, 16, 28, 28])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 16, 28, 28]) torch.Size([1, 16, 14, 14])\n",
      "Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) torch.Size([1, 16, 14, 14]) torch.Size([1, 32, 14, 14])\n",
      "ReLU() torch.Size([1, 32, 14, 14]) torch.Size([1, 32, 14, 14])\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) torch.Size([1, 32, 14, 14]) torch.Size([1, 32, 7, 7])\n",
      "Flatten(start_dim=1, end_dim=-1) torch.Size([1, 32, 7, 7]) torch.Size([1, 1568])\n",
      "Linear(in_features=1568, out_features=10, bias=True) torch.Size([1, 1568]) torch.Size([1, 10])\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m lrp \u001b[39m=\u001b[39m LRP_0(model, image\u001b[39m.\u001b[39mto(dev))[\u001b[39m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(lrp\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 9\u001b[0m img \u001b[39m=\u001b[39m lrp\u001b[39m.\u001b[39;49msqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mpermute(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     10\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m     11\u001b[0m plt\u001b[39m.\u001b[39mimshow(img)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "image, label = next(iter(test_loader))\n",
    "model(image.to(dev))\n",
    "print(image.shape)\n",
    "img = image.squeeze(0).permute(1,2,0).numpy()\n",
    "plt.imshow(img)\n",
    "lrp = LRP_0(model, image.to(dev))\n",
    "print(lrp.shape)\n",
    "img = lrp.squeeze(0).permute(1,2,0).numpy()\n",
    "plt.figure()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
