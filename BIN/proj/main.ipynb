{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from eval import accuracy\n",
    "from model import MnistCNN\n",
    "from train import fit, evaluate\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SIZE = 28 * 28\n",
    "DATASET = MNIST(root='data/', download=True, train=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "\n",
    "def split_indices(n, val_pct):\n",
    "    # Determine size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "\n",
    "    idxs = np.random.permutation(n)\n",
    "\n",
    "    return idxs[n_val:], idxs[:n_val]\n",
    "\n",
    "train_indexes, validation_indexes = split_indices(len(DATASET), 0.2)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indexes)\n",
    "train_loader = DataLoader(DATASET, BATCH_SIZE, sampler=train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(validation_indexes)\n",
    "val_loader = DataLoader(DATASET, BATCH_SIZE, sampler=val_sampler)\n",
    "\n",
    "loss_fun = F.cross_entropy\n",
    "\n",
    "def predict_image(image, model):\n",
    "    xb = image.unsqueeze(0).to(dev)\n",
    "    yb = model(xb)\n",
    "    yb = yb.to(dev)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()\n",
    "\n",
    "def plot_graph(rng ,acc_list, lost_list, title):\n",
    "    plt.plot(rng, acc_list, '-b', label='accuracy')\n",
    "    plt.plot(rng, lost_list, '-r', label='loss')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(\"amount pruned\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.1383, accuracy: 0.9564\n",
      "Epoch 2, loss: 0.0985, accuracy: 0.9702\n",
      "Epoch 3, loss: 0.0873, accuracy: 0.9731\n",
      "Epoch 4, loss: 0.0739, accuracy: 0.9771\n",
      "Epoch 5, loss: 0.0640, accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = MnistCNN().to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "fit(5, model, loss_fun, optimizer, train_loader, val_loader, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0533, accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MNIST(root='data/', train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "test_loss, total, test_acc = evaluate(model, loss_fun, test_loader, metric=accuracy)\n",
    "print(f\"Loss: {test_loss:.4f}, accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output\n",
    "    return hook\n",
    "\n",
    "for name, module in model.named_children():\n",
    "    module.register_forward_hook(get_activation(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def LRP_0(model : nn.Module, activations): \n",
    "#     T = activations['out'][0].cpu().detach().numpy().tolist()\n",
    "#     index = T.index(max(T))\n",
    "#     T = np.abs(np.array(T)) * 0\n",
    "#     T[index] = 1\n",
    "#     T = torch.FloatTensor(T)\n",
    "#     lrp = [None] * len(list(model.named_modules())) + [(activations['out'][0].cpu().data * T).data + 1e-6]\n",
    "#     activations['out'][0] = activations['out'][0].data.requires_grad_(True)\n",
    "#     z = newlayer(model.flatten).forward(activations['out'][0])\n",
    "#     return z\n",
    "\n",
    "def LRP_0(model : nn.Module, X):\n",
    "    layers = [module for module in model.named_children() if not isinstance(module, torch.nn.Sequential)]\n",
    "    L = len(layers)\n",
    "    A = [X] + [X] * L \n",
    "    for layer in range(L):\n",
    "        A[layer + 1] = layers[layer][1].forward(A[layer])\n",
    "\n",
    "    T = A[-1].cpu().detach().numpy().tolist()[0]\n",
    "    index = T.index(max(T))\n",
    "    T = np.abs(np.array(T)) * 0\n",
    "    T[index] = 1\n",
    "    T = torch.FloatTensor(T)\n",
    "    # Create the list of relevances with (L + 1) elements and assign the value of the last one \n",
    "    R = [None] * L + [(A[-1].cpu() * T).data + 1e-6]\n",
    "    print(T)\n",
    "    for layer in range(0, L)[::-1]:\n",
    "        print(layers[layer])\n",
    "        A[layer] = A[layer].data.requires_grad_(True)\n",
    "        z = newlayer(layers[layer][1]).forward(A[layer]) + 1e-9\n",
    "        return z\n",
    "        break\n",
    "\n",
    "\n",
    "def newlayer(layer : nn.Module) -> nn.Module:\n",
    "    layer = copy.deepcopy(layer)\n",
    "    layer.weight = torch.nn.Parameter(layer.weight)\n",
    "    layer.bias = torch.nn.Parameter(layer.bias)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conv1', Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))), ('relu1', ReLU()), ('pool1', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('conv2', Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))), ('relu2', ReLU()), ('pool2', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('flatten', Flatten(start_dim=1, end_dim=-1)), ('out', Linear(in_features=1568, out_features=10, bias=True))]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "('out', Linear(in_features=1568, out_features=10, bias=True))\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "for image, label in test_loader:\n",
    "    model(image.to(dev))\n",
    "    break\n",
    "# for name, module in model.named_children():\n",
    "#     print(name)\n",
    "lrp = LRP_0(model, image.to(dev))\n",
    "print(lrp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
